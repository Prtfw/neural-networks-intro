{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression using `tensorflow`\n",
    "\n",
    "Just as with `theano`, we'll use `tensorflow` to build up a computational graph, take advantage of it's automatic differentiation, and solve for the coefficients in our logistic regression. \n",
    "\n",
    "## Computational Graphs for Logistic Regression \n",
    "\n",
    "Let's keep the computational graph visuals around for reference: \n",
    "\n",
    "### Forward Propagation\n",
    "\n",
    "<img src=\"https://github.com/sallamander/neural-networks-intro/blob/master/mini-books/shallow-neural-networks/imgs/custom/logistic_comp_graph_condensed_forprop.png?raw=true\" width=300\\>\n",
    "\n",
    "### Backward Propagation\n",
    "\n",
    "<img src=\"https://github.com/sallamander/neural-networks-intro/blob/master/mini-books/shallow-neural-networks/imgs/custom/logistic_comp_graph_condensed_backprop.png?raw=true\" width=400\\>\n",
    "\n",
    "### Building a computational graph with `tensorflow`\n",
    "\n",
    "The biggest difference between the `numpy` implementation and the `tensorflow` implementation of our logistic regression problem is that we'll be able to use the automatic differentiation that `tensorflow` offers. In comparing `theano` to `tensorflow`, we'll see similar syntax when building up the graph, but different syntax when actually performing the iterations of gradient descent. Let's dive in..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from datasets.general import gen_multiple_logistic\n",
    "from utils.plotting import plot_errors\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tensorflow_graph(): \n",
    "    learning_rate = 0.1\n",
    "    # 1. Define placeholder matrices for inputs.\n",
    "    xs = tf.placeholder(tf.float64, name='xs') \n",
    "    ys = tf.placeholder(tf.float64, name='ys')\n",
    "    # 2. Define randomly initialized floats for our betas. \n",
    "    betas = tf.Variable(np.random.random(size=(4, 1)), name='betas')\n",
    "\n",
    "    # 3. Define the equation that generates predictions.\n",
    "    yhats = 1 / (1 + tf.exp(-tf.matmul(xs, betas)))\n",
    "    # 4. Define the equation that generates our errors. \n",
    "    es = -(ys * tf.log(yhats) + (1 - ys) * tf.log(1 - yhats))\n",
    "    # 5. Define the aggregate cost (mean of squared errors)\n",
    "    E = tf.reduce_mean(es)\n",
    "    # 6. Take advantage of `tensorflows` optimizer to automate differentiation\n",
    "    #    as well as the update step. \n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    train = optimizer.minimize(E)\n",
    "    \n",
    "    return E, betas, train, xs, ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our logistic regression solution with `tensorflow` is going to differ from our `theano` solution ([notebook 3c](https://github.com/sallamander/neural-networks-intro/blob/master/mini-books/shallow-neural-networks/03-logistic/3c_nn_th.ipynb)) in the same way it did for multiple linear regression - `get_tensorflow_graph` will look incredibly similar, with differences in the calculations for the predicted values (`yhats`) and errors (`es`). It will, however, still return back the steps necessary to perform forward and backward propagation as multiple pieces, rather than one callable function as we saw with `theano`. As for the individual pieces, steps `1-5` will still correspond to the forward pass and step `6` the backward pass.\n",
    "\n",
    "In terms of the individual pieces being returned: \n",
    "\n",
    "1. The cross entropy error (`E`) is returned so that we can track it through each iteration. \n",
    "2. `betas` are returned so that we can reference them below to initialize them (see the `tf.intialize_variables` call; we could also use `tf.initialize_all_variables`). Note the generation of `betas` as a [Variable object](https://www.tensorflow.org/versions/r0.9/get_started/basic_usage.html#variables) - this is what allows our coefficient values to be updated and shared across iterations. \n",
    "3. `train` holds the magic of our computational graph and is effectively what allows us to have `tensorflow` handle differentiation for us.  Here, we simply feed the quantity that we want minimized (the **binary crossentropy**, `E`) to a [tensorflow Optimizer](https://www.tensorflow.org/versions/r0.10/api_docs/python/train.html), which provides us with a simple interface for performing gradient descent. \n",
    "\n",
    " When we call [minimize](https://www.tensorflow.org/versions/r0.10/api_docs/python/train.html#processing-gradients-before-applying-them) on this `Optimizer`, it builds the calculation of the derivatives and the performing of the updates into our computational graph. It by default takes the derivatives of all of the `tf.Variable` objects that it finds in the computational graph prior to that step. Here, this is just `betas`. \n",
    " \n",
    " When `train` is run in a session below, any steps that are necessary to perform the minimization step will be run, which in effect is every step that is part of the forward and backward propagation.\n",
    "4. Finally, `xs` and `ys` are placeholders for our data, and are returned so that we can tell `tensorflow` exactly what part of our graph the real data should line up with. \n",
    "\n",
    "The next step will be to use one of the `Session` objects we've discussed to perform gradient descent and learn the true values for each beta coefficient in `betas`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Error: 0.00019970865003271206\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAEZCAYAAAC0HgObAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZlXlwGJmZlXlwGJmZlXlwGJmZlX1P47nSpr674YFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1105c8cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Randomly generate our betas and number of observations, used to generate \n",
    "# fake data to fit. We should have a minimum of 4 obs., since we have \n",
    "# 4 coefficients. \n",
    "true_betas_array = np.random.randint(2, 10, size=4)\n",
    "n_obs = np.random.randint(9500, 10500) \n",
    "\n",
    "# Generate the tensorflow graph. This is in a function so that we can run this cell multiple \n",
    "# times and obtain different randomly generated values for `true_betas_array`. \n",
    "E, betas, train, xs, ys = get_tensorflow_graph()\n",
    "\n",
    "# Generate the data that follows a logistic relationship specified by `true_betas_array`.\n",
    "x, y = gen_multiple_logistic(true_betas_array, n_obs)\n",
    "y = y > 0.5\n",
    "\n",
    "# Define the initialization operation. \n",
    "init = tf.initialize_variables([betas])\n",
    "with tf.Session() as sess: \n",
    "    sess.run(init) # Perform the actual initialization operation. \n",
    "\n",
    "    # Perform iterations (forward & backward prop.) over the tensorflow graph\n",
    "    binary_crossentropy_lst = []\n",
    "    for step in range(50000):\n",
    "        binary_crossentropy, _ = sess.run([E, train], feed_dict={xs : x, ys : y})  \n",
    "        binary_crossentropy_lst.append(binary_crossentropy)\n",
    "\n",
    "plot_errors(binary_crossentropy_lst, iterations=(100, 50000))\n",
    "print(\"Final Error: {}\".format(binary_crossentropy_lst[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Just as with all of our prior implementations using `tensorflow`, we'll run gradient descent for our logistic regression problem via a `Session` object. This [Session object](https://www.tensorflow.org/versions/r0.9/api_docs/python/client.html#session-management) allows us to encapsulate all of the calculations and implementation details of our graph (or any graph) into a single environment. When running multiple graphs, each of which might have their own specialized environment, this is incredibly helpful. \n",
    "\n",
    "After initializing a `Session` object, our first step is to [initialize any variables](https://www.tensorflow.org/versions/r0.9/how_tos/variables/index.html#initialization) that are going to be used in the graph. Here, this is just the `betas` variable. Once we have created a `Session` object and initialized all of our variables, we can run parts of our graph or ask for values of variables by passing them into `Session.run`. Any time that we want to view the values held in the `betas` variable, for example, we run:  \n",
    "\n",
    "```\n",
    "Session.run(betas)\n",
    "``` \n",
    "\n",
    "If we run this **before** any iterations of gradient descent have been performed, we'll be given back the initial values of each of the coefficients in `betas`. In order to run one iteration of the gradient descent procedure, we pass `train` into `Session.run`: \n",
    "\n",
    "```\n",
    "Session.run(train, feed_dict={xs : x, ys : y})\n",
    "```\n",
    "\n",
    "\n",
    "When this piece (or any piece) of the computational graph is passed into `Session.run`, any steps necessary to compute what is asked for will be run. For `train`, this is every step of the computational graph - the forward propagation (steps `1-5`) and the backward propagation / update (step `6`). To perform these steps, `xs` and `ys` are necessary, and are passed in via the `feed_dict` argument. The keys of the `feed_dict` are the variables referring to the placeholder objects in the graph, and the values are the data that will be used for those placeholders. After running `train`, the `betas` will no longer correspond to their original values. Note that in the code above we also ask for `E` back, which is what allows us to track our binary crossentropy through each iteration. \n",
    "\n",
    "Finally, if we run `train` through `Session.run` in a loop (as we do), we see that we can solve our logistic regression problem using this graph built in `tensorflow`.  \n",
    "\n",
    "Next, we'll code this up with `keras`. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
